{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfcf89ce-0f60-4fda-b998-ac1c17aa26bd",
   "metadata": {},
   "source": [
    "\n",
    "# Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765ba4cc-0595-4c14-878c-155c1706846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#pip install datasets\n",
    "#!pip install transformers[torch]\n",
    "#!pip install accelerate>=0.20.1\n",
    "#!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1299cb33-e289-409a-9ac6-f5232806034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer,TrainingArguments, pipeline, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b6996-7b48-4eac-b6fc-40dec509421c",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff885809-ebce-417b-ac65-f7fb1afdd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"Data_with_explanations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b155f545-89a4-4fab-8907-f921127a3b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of clicking on the 'Ajoute...</td>\n",
       "      <td>To fill in the characteristics of Finition</td>\n",
       "      <td>The purpose of clicking the \"Ajouter Finition\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What types of information can be filled in whe...</td>\n",
       "      <td>Caractéristiques, Motorisation, Transmission e...</td>\n",
       "      <td>In the context of automotive design and functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the first category of information that...</td>\n",
       "      <td>Caractéristiques</td>\n",
       "      <td>When clicking on \"Ajouter fin\", I will explain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is there a separate section for motorization-r...</td>\n",
       "      <td>Yes, it's called Motorisation</td>\n",
       "      <td>Yes, the provided sections are separated into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the last category of information that ...</td>\n",
       "      <td>Equipements</td>\n",
       "      <td>The \"last category of information that can be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>What are the steps to follow to choose a product?</td>\n",
       "      <td>The client must follow the steps by choosing t...</td>\n",
       "      <td>To choose a product, the following steps can b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>What is required of the client at the beginning?</td>\n",
       "      <td>The client must choose the product according t...</td>\n",
       "      <td>The client must first select from the offered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>What action does the client need to take first?</td>\n",
       "      <td>Clicking on 'Financer'.</td>\n",
       "      <td>Sure! Let's break down how the client needs to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>How can the client proceed with selecting a pr...</td>\n",
       "      <td>By choosing the product according to the offer...</td>\n",
       "      <td>Explanation:\\n\\nThe client should follow these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>What is the next step after product selection?</td>\n",
       "      <td>Clicking on 'Financer'.</td>\n",
       "      <td>The \"Clicking on 'Financer'\" part of the instr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    What is the purpose of clicking on the 'Ajoute...   \n",
       "1    What types of information can be filled in whe...   \n",
       "2    What is the first category of information that...   \n",
       "3    Is there a separate section for motorization-r...   \n",
       "4    What is the last category of information that ...   \n",
       "..                                                 ...   \n",
       "745  What are the steps to follow to choose a product?   \n",
       "746   What is required of the client at the beginning?   \n",
       "747    What action does the client need to take first?   \n",
       "748  How can the client proceed with selecting a pr...   \n",
       "749     What is the next step after product selection?   \n",
       "\n",
       "                                              response  \\\n",
       "0           To fill in the characteristics of Finition   \n",
       "1    Caractéristiques, Motorisation, Transmission e...   \n",
       "2                                     Caractéristiques   \n",
       "3                        Yes, it's called Motorisation   \n",
       "4                                          Equipements   \n",
       "..                                                 ...   \n",
       "745  The client must follow the steps by choosing t...   \n",
       "746  The client must choose the product according t...   \n",
       "747                            Clicking on 'Financer'.   \n",
       "748  By choosing the product according to the offer...   \n",
       "749                            Clicking on 'Financer'.   \n",
       "\n",
       "                                           explanation  \n",
       "0    The purpose of clicking the \"Ajouter Finition\"...  \n",
       "1    In the context of automotive design and functi...  \n",
       "2    When clicking on \"Ajouter fin\", I will explain...  \n",
       "3    Yes, the provided sections are separated into ...  \n",
       "4    The \"last category of information that can be ...  \n",
       "..                                                 ...  \n",
       "745  To choose a product, the following steps can b...  \n",
       "746  The client must first select from the offered ...  \n",
       "747  Sure! Let's break down how the client needs to...  \n",
       "748  Explanation:\\n\\nThe client should follow these...  \n",
       "749  The \"Clicking on 'Financer'\" part of the instr...  \n",
       "\n",
       "[750 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"Data_with_explanations.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb4e44-366c-4a0b-8168-e0ea13036af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ee17f-7e7f-4585-9ddb-48d86f9e5dbc",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da5468-fa3c-4c2a-b77d-3aa896837129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9b1bc27b454bfa9d67541fbad60e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  15%|#5        | 83.9M/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "student_checkpoint = \"gpt2\"\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_checkpoint)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(student_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246aea1e-9e60-4732-a552-2d0cf4adcdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_checkpoint = \"gpt2-xl\"\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_checkpoint)\n",
    "teacher_model = AutoModelForCausalLM.from_pretrained(teacher_checkpoint).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd4c6ec3-7e51-4e53-84ee-38f489048c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7650f9e120549b6a9ac72a7c81564a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_text(batch):\n",
    "  return student_tokenizer(batch[\"question\"], padding=\"max_length\", truncation=True)\n",
    "tokenized_datasets = dataset.map(tokenize_text, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a5c0a-a9a9-4b50-be64-904192728c95",
   "metadata": {},
   "source": [
    "# Prepare training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049f1e6-20cc-4153-b757-c0520209396c",
   "metadata": {},
   "source": [
    "Create trainer class and loss function compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcc1ae20-c38c-44f1-b47b-bed5e13e6b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "757dbf48-3cdc-418a-9837-b93611dfbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeDistillationTrainingArguments(TrainingArguments):\n",
    "  def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.alpha = alpha\n",
    "    self.temperature = temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "470b4a07-4d92-49a7-90ad-eca49f2f3dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeDistillationTrainer(Trainer):\n",
    "  def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.teacher_model = teacher_model\n",
    "\n",
    "  def compute_loss(self, model, inputs, return_outputs=False):\n",
    "    #Extract cross-entropy loss and logits from student\n",
    "    outputs_student = model(**inputs)\n",
    "    loss_ce = outputs_student.loss\n",
    "    logits_student = outputs_student.logits\n",
    "    # Extract logits from teacher\n",
    "    outputs_teacher = self.teacher_model(**inputs)\n",
    "    logits_teacher = outputs_teacher.logits\n",
    "     #Computing distillation loss by Softening probabilities\n",
    "    loss_fct = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    loss_kd = self.args.temperature ** 2 * loss_fct(\n",
    "                F.log_softmax(logits_student / self.args.temperature, dim=-1),\n",
    "                F.softmax(logits_teacher / self.args.temperature, dim=-1))\n",
    "\n",
    "    loss = self.args.alpha * loss_ce + (1. - self.args.alpha) * loss_kd\n",
    "    return (loss, outputs_student) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00c1f820-eca2-4d71-bb7d-2f529fa090cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f79bfe96d14394bde0af4b249641fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b1777-994f-4b4e-b180-a2ad2e29e93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df73f01e-7588-4773-8f22-c1cad7c53a15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m finetuned_student_ckpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_aziz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m## Training Arguments for DistillationTrainer\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m student_training_args \u001b[38;5;241m=\u001b[39m \u001b[43mKnowledgeDistillationTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinetuned_student_ckpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m, in \u001b[0;36mKnowledgeDistillationTrainingArguments.__init__\u001b[1;34m(self, alpha, temperature, *args, **kwargs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m----> 3\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m=\u001b[39m alpha\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature \u001b[38;5;241m=\u001b[39m temperature\n",
      "File \u001b[1;32m<string>:134\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Ons\\IA-Ollama-RAG-IMPL\\src\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1791\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[1;32m-> 1791\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_tokens_across_devices:\n",
      "File \u001b[1;32mc:\\Users\\Ons\\IA-Ollama-RAG-IMPL\\src\\.venv\\Lib\\site-packages\\transformers\\training_args.py:2313\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2309\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2310\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[0;32m   2311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2312\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ons\\IA-Ollama-RAG-IMPL\\src\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:62\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m     60\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[1;32mc:\\Users\\Ons\\IA-Ollama-RAG-IMPL\\src\\.venv\\Lib\\site-packages\\transformers\\training_args.py:2186\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   2185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 2186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2188\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2189\u001b[0m         )\n\u001b[0;32m   2190\u001b[0m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[0;32m   2191\u001b[0m accelerator_state_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_configured_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[1;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "batch_size = 48\n",
    "finetuned_student_ckpt = \"student_aziz\"\n",
    "\n",
    "## Training Arguments for DistillationTrainer\n",
    "student_training_args = KnowledgeDistillationTrainingArguments(\n",
    "    output_dir=finetuned_student_ckpt, \n",
    "    evaluation_strategy = \"epoch\",\n",
    "    num_train_epochs=3, \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size, \n",
    "    alpha=1, \n",
    "    weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36ffa5ce-97f7-447a-a0db-c83fb9215fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'accelerate\": Expected package name at the start of dependency specifier\n",
      "    'accelerate\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2ForSequenceClassification\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d06b6-e402-432f-9aeb-8ed1056c6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%%time\n",
    "distilbert_trainer = KnowledgeDistillationTrainer(\n",
    "    model_init=student_init,\n",
    "    teacher_model=teacher_model, \n",
    "    args=student_training_args,\n",
    "    train_dataset=clinc_tokenized['train'], \n",
    "    eval_dataset=clinc_tokenized['validation'],\n",
    "    compute_metrics=compute_metrics, \n",
    "    tokenizer=student_tokenizer)\n",
    "\n",
    "distilbert_trainer.train()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
